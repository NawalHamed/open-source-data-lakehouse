[2025-06-17T06:07:36.977+0000] {processor.py:157} INFO - Started process (PID=199) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:07:36.980+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:07:36.990+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:07:36.989+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:07:37.207+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:07:38.008+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:07:38.008+0000] {manager.py:501} INFO - Created Permission View: can read on DAG:iceberg_table_creator
[2025-06-17T06:07:38.066+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:07:38.066+0000] {manager.py:501} INFO - Created Permission View: can delete on DAG:iceberg_table_creator
[2025-06-17T06:07:38.100+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:07:38.100+0000] {manager.py:501} INFO - Created Permission View: can edit on DAG:iceberg_table_creator
[2025-06-17T06:07:38.166+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:07:38.166+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:07:38.248+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:07:38.247+0000] {dag.py:2929} INFO - Creating ORM DAG for iceberg_table_creator
[2025-06-17T06:07:38.263+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:07:38.250+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:07:38.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.637 seconds
[2025-06-17T06:08:08.721+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:08:08.725+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:08:08.726+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:08:08.726+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:08:08.776+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:08:08.910+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:08:08.910+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:08:08.957+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:08:08.957+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:08:09.136+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.418 seconds
[2025-06-17T06:08:39.350+0000] {processor.py:157} INFO - Started process (PID=209) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:08:39.352+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:08:39.361+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:08:39.360+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:08:39.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:08:39.503+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:08:39.503+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:08:39.573+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:08:39.572+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:08:39.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.311 seconds
[2025-06-17T06:09:10.031+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:09:10.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:09:10.034+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:09:10.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:09:10.081+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:09:10.301+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:09:10.298+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:09:10.410+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:09:10.409+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:09:10.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.461 seconds
[2025-06-17T06:09:41.032+0000] {processor.py:157} INFO - Started process (PID=219) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:09:41.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:09:41.047+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:09:41.034+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:09:41.140+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:09:41.228+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:09:41.228+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:09:41.299+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:09:41.298+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:09:41.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.386 seconds
[2025-06-17T06:10:11.893+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:10:11.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:10:11.910+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:10:11.910+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:10:11.981+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:10:12.144+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:10:12.132+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:10:12.211+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:10:12.211+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:10:12.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.452 seconds
[2025-06-17T06:10:42.940+0000] {processor.py:157} INFO - Started process (PID=229) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:10:42.941+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:10:42.943+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:10:42.942+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:10:43.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:10:43.143+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:10:43.143+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:10:43.239+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:10:43.239+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:10:43.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.422 seconds
[2025-06-17T06:11:13.850+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:11:13.852+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:11:13.854+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:11:13.853+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:11:13.904+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:11:14.006+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:11:14.005+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:11:14.026+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:11:14.026+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:11:14.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.262 seconds
[2025-06-17T06:11:44.300+0000] {processor.py:157} INFO - Started process (PID=239) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:11:44.301+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:11:44.316+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:11:44.315+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:11:44.378+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:11:44.506+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:11:44.505+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:11:44.530+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:11:44.530+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:11:44.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.301 seconds
[2025-06-17T06:12:14.848+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:12:14.853+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:12:14.854+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:12:14.854+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:12:14.946+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:12:15.104+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:12:15.104+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:12:15.168+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:12:15.158+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:12:15.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.421 seconds
[2025-06-17T06:12:45.644+0000] {processor.py:157} INFO - Started process (PID=249) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:12:45.646+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:12:45.657+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:12:45.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:12:45.761+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:12:45.890+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:12:45.890+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:12:45.919+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:12:45.919+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:12:45.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.374 seconds
[2025-06-17T06:13:16.369+0000] {processor.py:157} INFO - Started process (PID=254) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:13:16.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:13:16.373+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:13:16.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:13:16.432+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:13:16.540+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:13:16.540+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:13:16.588+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:13:16.587+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:13:16.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.369 seconds
[2025-06-17T06:13:46.823+0000] {processor.py:157} INFO - Started process (PID=259) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:13:46.824+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:13:46.841+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:13:46.825+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:13:46.902+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:13:46.963+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:13:46.962+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:13:47.007+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:13:47.007+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:13:47.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.225 seconds
[2025-06-17T06:14:17.328+0000] {processor.py:157} INFO - Started process (PID=264) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:14:17.329+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:14:17.337+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:14:17.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:14:17.379+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:14:17.436+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:14:17.435+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:14:17.487+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:14:17.486+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:14:17.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.288 seconds
[2025-06-17T06:14:48.100+0000] {processor.py:157} INFO - Started process (PID=269) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:14:48.101+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:14:48.102+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:14:48.102+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:14:48.163+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:14:48.303+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:14:48.303+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:14:48.384+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:14:48.384+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:14:48.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.420 seconds
[2025-06-17T06:15:19.096+0000] {processor.py:157} INFO - Started process (PID=274) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:15:19.114+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:15:19.126+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:15:19.126+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:15:19.235+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:15:19.335+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:15:19.335+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:15:19.394+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:15:19.393+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:15:19.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.398 seconds
[2025-06-17T06:15:50.118+0000] {processor.py:157} INFO - Started process (PID=279) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:15:50.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:15:50.126+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:15:50.125+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:15:50.208+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:15:50.359+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:15:50.359+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:15:50.397+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:15:50.396+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:15:50.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.359 seconds
[2025-06-17T06:16:21.039+0000] {processor.py:157} INFO - Started process (PID=284) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:16:21.042+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:16:21.044+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:16:21.043+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:16:21.131+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:16:21.233+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:16:21.233+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:16:21.322+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:16:21.321+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:16:21.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.357 seconds
[2025-06-17T06:16:51.512+0000] {processor.py:157} INFO - Started process (PID=289) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:16:51.513+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:16:51.528+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:16:51.528+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:16:51.622+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:16:51.742+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:16:51.742+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:16:51.788+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:16:51.774+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:16:51.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.375 seconds
[2025-06-17T06:17:22.355+0000] {processor.py:157} INFO - Started process (PID=294) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:17:22.371+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:17:22.372+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:17:22.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:17:22.464+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:17:22.614+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:17:22.614+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:17:22.693+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:17:22.693+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:17:22.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.480 seconds
[2025-06-17T06:17:53.090+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:17:53.105+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:17:53.106+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:17:53.106+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:17:53.169+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:17:53.298+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:17:53.298+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:17:53.366+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:17:53.366+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:17:53.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.430 seconds
[2025-06-17T06:18:23.992+0000] {processor.py:157} INFO - Started process (PID=304) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:18:23.993+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:18:23.994+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:18:23.994+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:18:24.082+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:18:24.155+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:18:24.154+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:18:24.206+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:18:24.205+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:18:24.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.466 seconds
[2025-06-17T06:18:55.198+0000] {processor.py:157} INFO - Started process (PID=309) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:18:55.203+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:18:55.205+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:18:55.205+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:18:55.296+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:18:55.448+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:18:55.448+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:18:55.544+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:18:55.544+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:18:55.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.471 seconds
[2025-06-17T06:19:26.104+0000] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:19:26.109+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:19:26.112+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:19:26.111+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:19:26.192+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:19:26.369+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:19:26.369+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:19:26.424+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:19:26.424+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:19:26.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.463 seconds
[2025-06-17T06:19:56.955+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:19:56.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:19:56.957+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:19:56.957+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:19:57.108+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:19:57.249+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:19:57.249+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:19:57.285+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:19:57.285+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:19:57.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.399 seconds
[2025-06-17T06:21:19.024+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:21:19.035+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:21:19.051+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:21:19.050+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:21:19.165+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:21:19.305+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:21:19.304+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:21:19.413+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:21:19.413+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:21:19.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.580 seconds
[2025-06-17T06:21:49.847+0000] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:21:49.862+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:21:49.864+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:21:49.864+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:21:49.968+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:21:50.204+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:21:50.204+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:21:50.302+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:21:50.302+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:21:50.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.612 seconds
[2025-06-17T06:22:20.784+0000] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:22:20.785+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:22:20.786+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:22:20.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:22:20.876+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:22:21.024+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:22:21.024+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:22:21.069+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:22:21.068+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:22:21.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.397 seconds
[2025-06-17T06:22:52.087+0000] {processor.py:157} INFO - Started process (PID=213) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:22:52.118+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:22:52.149+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:22:52.120+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:22:52.517+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:22:52.970+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:22:52.970+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:22:53.230+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:22:53.230+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:22:53.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.505 seconds
[2025-06-17T06:23:24.005+0000] {processor.py:157} INFO - Started process (PID=218) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:23:24.034+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:23:24.046+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:23:24.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:23:24.396+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:23:24.882+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:23:24.882+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:23:25.295+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:23:25.294+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:23:25.645+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.839 seconds
[2025-06-17T06:23:56.441+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:23:56.467+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:23:56.486+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:23:56.480+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:23:57.848+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:23:58.478+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:23:58.478+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:23:58.737+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:23:58.737+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:23:59.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 2.599 seconds
[2025-06-17T06:24:29.347+0000] {processor.py:157} INFO - Started process (PID=231) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:24:29.353+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:24:29.354+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:24:29.354+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:24:29.473+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:24:29.813+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:24:29.806+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:24:29.896+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:24:29.896+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:24:30.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.721 seconds
[2025-06-17T06:25:00.302+0000] {processor.py:157} INFO - Started process (PID=236) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:25:00.309+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:25:00.311+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:25:00.310+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:25:00.358+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:25:00.591+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:25:00.590+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:25:00.681+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:25:00.680+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:25:00.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.449 seconds
[2025-06-17T06:25:31.285+0000] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:25:31.287+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:25:31.289+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:25:31.288+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:25:31.390+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:25:31.490+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:25:31.490+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:25:31.548+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:25:31.548+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:25:31.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.341 seconds
[2025-06-17T06:26:01.885+0000] {processor.py:157} INFO - Started process (PID=246) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:26:01.895+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:26:01.901+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:26:01.900+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:26:01.963+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:26:02.065+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:26:02.065+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:26:02.095+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:26:02.095+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:26:02.252+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.371 seconds
[2025-06-17T06:26:32.921+0000] {processor.py:157} INFO - Started process (PID=251) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:26:32.937+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:26:32.939+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:26:32.939+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:26:32.990+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:26:33.168+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:26:33.168+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:26:33.229+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:26:33.229+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:26:33.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.460 seconds
[2025-06-17T06:27:04.323+0000] {processor.py:157} INFO - Started process (PID=256) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:27:04.335+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:27:04.337+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:27:04.336+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:27:04.435+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:27:04.487+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:27:04.487+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:27:04.535+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:27:04.534+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:27:04.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.374 seconds
[2025-06-17T06:27:34.950+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:27:34.952+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:27:34.953+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:27:34.952+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:27:35.042+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:27:35.279+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:27:35.273+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:27:38.553+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:27:38.553+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:27:38.730+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 3.798 seconds
[2025-06-17T06:28:09.036+0000] {processor.py:157} INFO - Started process (PID=266) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:28:09.054+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:28:09.063+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:28:09.055+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:28:09.187+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:28:09.332+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:28:09.332+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:28:10.005+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:28:10.004+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:28:10.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.043 seconds
[2025-06-17T06:28:40.817+0000] {processor.py:157} INFO - Started process (PID=271) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:28:40.823+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:28:40.825+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:28:40.824+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:28:40.953+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:28:41.624+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:28:41.616+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:28:41.677+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:28:41.677+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:28:41.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.999 seconds
[2025-06-17T06:29:12.240+0000] {processor.py:157} INFO - Started process (PID=277) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:29:12.312+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:29:12.418+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:29:12.400+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:29:12.681+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:29:13.290+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:29:13.289+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:29:13.490+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:29:13.490+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:29:13.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.610 seconds
[2025-06-17T06:29:44.207+0000] {processor.py:157} INFO - Started process (PID=284) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:29:44.233+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:29:44.235+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:29:44.235+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:29:44.346+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:29:44.465+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:29:44.464+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:29:44.522+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:29:44.517+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:29:44.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.480 seconds
[2025-06-17T06:30:15.191+0000] {processor.py:157} INFO - Started process (PID=289) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:30:15.192+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:30:15.208+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:30:15.208+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:30:15.350+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:30:15.452+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:30:15.451+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:30:15.508+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:30:15.493+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:30:15.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.460 seconds
[2025-06-17T06:30:45.983+0000] {processor.py:157} INFO - Started process (PID=294) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:30:45.984+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:30:45.991+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:30:45.990+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:30:46.093+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:30:46.291+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:30:46.290+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:30:46.361+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:30:46.361+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:30:46.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.461 seconds
[2025-06-17T06:31:17.168+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:31:17.181+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:31:17.208+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:31:17.207+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:31:17.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:31:17.600+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:31:17.599+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:31:17.671+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:31:17.671+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:31:17.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.569 seconds
[2025-06-17T06:31:47.943+0000] {processor.py:157} INFO - Started process (PID=304) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:31:47.945+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:31:47.946+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:31:47.946+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:31:48.014+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:31:48.064+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:31:48.064+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:31:48.084+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:31:48.084+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:31:48.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.357 seconds
[2025-06-17T06:32:18.619+0000] {processor.py:157} INFO - Started process (PID=309) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:32:18.625+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:32:18.627+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:32:18.626+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:32:18.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:32:18.849+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:32:18.848+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:32:18.920+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:32:18.920+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:32:19.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.497 seconds
[2025-06-17T06:32:49.885+0000] {processor.py:157} INFO - Started process (PID=314) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:32:49.902+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:32:49.903+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:32:49.903+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:32:49.966+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:32:50.084+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:32:50.083+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:32:50.182+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:32:50.182+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:32:50.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.450 seconds
[2025-06-17T06:33:20.769+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:33:20.771+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:33:20.787+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:33:20.786+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:33:20.889+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:33:21.081+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:33:21.081+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:33:21.161+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:33:21.161+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:33:21.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.512 seconds
[2025-06-17T06:33:52.022+0000] {processor.py:157} INFO - Started process (PID=324) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:33:52.024+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:33:52.025+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:33:52.025+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:33:52.112+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:33:52.173+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:33:52.173+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:33:52.255+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:33:52.254+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:33:52.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.380 seconds
[2025-06-17T06:34:22.869+0000] {processor.py:157} INFO - Started process (PID=329) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:34:22.870+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:34:22.871+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:34:22.871+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:34:22.918+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:34:22.969+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:34:22.969+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:34:22.990+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:34:22.990+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:34:23.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.217 seconds
[2025-06-17T06:34:53.741+0000] {processor.py:157} INFO - Started process (PID=334) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:34:53.742+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:34:53.743+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:34:53.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:34:53.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:34:54.059+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:34:54.058+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:34:54.141+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:34:54.141+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:34:54.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.550 seconds
[2025-06-17T06:35:24.618+0000] {processor.py:157} INFO - Started process (PID=339) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:35:24.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:35:24.637+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:35:24.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:35:24.753+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:35:24.874+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:35:24.873+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:35:24.984+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:35:24.984+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:35:25.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.460 seconds
[2025-06-17T06:35:55.828+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:35:55.830+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:35:55.847+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:35:55.847+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:35:55.880+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:35:55.996+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:35:55.995+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:35:56.077+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:35:56.077+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:35:56.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.368 seconds
[2025-06-17T06:36:26.782+0000] {processor.py:157} INFO - Started process (PID=349) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:36:26.784+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:36:26.785+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:36:26.785+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:36:26.945+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:36:27.062+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:36:27.057+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:36:27.092+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:36:27.087+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:36:27.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.478 seconds
[2025-06-17T06:36:57.682+0000] {processor.py:157} INFO - Started process (PID=354) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:36:57.683+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:36:57.700+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:36:57.700+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:36:57.763+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:36:57.832+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:36:57.823+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:36:57.861+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:36:57.861+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:36:57.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.259 seconds
[2025-06-17T06:37:28.466+0000] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:37:28.472+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:37:28.474+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:37:28.473+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:37:28.635+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:37:28.805+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:37:28.805+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:37:28.877+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:37:28.876+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:37:29.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.558 seconds
[2025-06-17T06:37:59.409+0000] {processor.py:157} INFO - Started process (PID=364) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:37:59.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:37:59.419+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:37:59.419+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:37:59.578+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:37:59.700+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:37:59.699+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:37:59.728+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:37:59.728+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:37:59.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.448 seconds
[2025-06-17T06:38:30.735+0000] {processor.py:157} INFO - Started process (PID=369) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:38:30.736+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:38:30.737+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:38:30.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:38:30.837+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:38:30.966+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:38:30.965+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:38:31.055+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:38:31.054+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:38:31.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.562 seconds
[2025-06-17T06:39:01.696+0000] {processor.py:157} INFO - Started process (PID=374) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:39:01.703+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:39:01.704+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:39:01.704+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:39:01.775+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:39:01.976+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:39:01.975+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:39:02.023+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:39:02.023+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:39:02.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.454 seconds
[2025-06-17T06:39:33.044+0000] {processor.py:157} INFO - Started process (PID=379) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:39:33.050+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:39:33.051+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:39:33.051+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:39:33.102+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:39:33.183+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:39:33.182+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:39:33.284+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:39:33.284+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:39:33.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.418 seconds
[2025-06-17T06:40:03.925+0000] {processor.py:157} INFO - Started process (PID=384) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:40:03.927+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:40:03.944+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:40:03.943+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:40:04.076+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:40:04.264+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:40:04.263+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:40:04.368+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:40:04.367+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:40:04.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.609 seconds
[2025-06-17T06:40:35.188+0000] {processor.py:157} INFO - Started process (PID=389) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:40:35.189+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:40:35.200+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:40:35.200+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:40:35.349+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:40:35.478+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:40:35.478+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:40:35.548+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:40:35.548+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:40:35.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.531 seconds
[2025-06-17T06:41:06.464+0000] {processor.py:157} INFO - Started process (PID=394) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:41:06.466+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:41:06.467+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:41:06.466+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:41:06.594+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:41:06.777+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:41:06.776+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:41:06.834+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:41:06.834+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:41:06.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.532 seconds
[2025-06-17T06:41:37.529+0000] {processor.py:157} INFO - Started process (PID=399) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:41:37.558+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:41:37.576+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:41:37.560+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:41:37.659+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:41:37.887+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:41:37.886+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:41:37.956+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:41:37.950+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:41:38.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.637 seconds
[2025-06-17T06:42:08.821+0000] {processor.py:157} INFO - Started process (PID=404) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:42:08.839+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:42:08.881+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:42:08.869+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:42:09.003+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:42:09.160+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:42:09.159+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:42:09.213+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:42:09.211+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:42:09.393+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.601 seconds
[2025-06-17T06:42:40.057+0000] {processor.py:157} INFO - Started process (PID=409) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:42:40.085+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:42:40.088+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:42:40.087+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:42:40.196+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:42:40.375+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:42:40.375+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:42:40.434+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:42:40.434+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:42:40.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.580 seconds
[2025-06-17T06:43:11.247+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:43:11.249+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:43:11.276+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:43:11.276+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:43:11.427+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:43:11.559+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:43:11.558+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:43:11.617+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:43:11.617+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:43:11.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.529 seconds
[2025-06-17T06:43:42.486+0000] {processor.py:157} INFO - Started process (PID=419) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:43:42.493+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:43:42.496+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:43:42.496+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:43:42.675+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:43:42.825+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:43:42.825+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:43:42.905+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:43:42.905+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:43:43.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.578 seconds
[2025-06-17T06:44:13.683+0000] {processor.py:157} INFO - Started process (PID=424) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:44:13.684+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:44:13.691+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:44:13.690+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:44:13.743+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:44:13.824+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:44:13.823+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:44:13.934+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:44:13.934+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:44:14.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.358 seconds
[2025-06-17T06:44:44.999+0000] {processor.py:157} INFO - Started process (PID=429) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:44:45.001+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:44:45.012+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:44:45.011+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:44:45.101+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:44:45.359+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:44:45.359+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:44:45.410+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:44:45.410+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:44:45.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.563 seconds
[2025-06-17T06:45:15.967+0000] {processor.py:157} INFO - Started process (PID=434) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:45:15.998+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:45:16.007+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:45:16.007+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:45:16.150+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:45:16.330+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:45:16.329+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:45:16.408+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:45:16.407+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:45:16.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.688 seconds
[2025-06-17T06:45:47.545+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:45:47.547+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:45:47.548+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:45:47.548+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:45:47.669+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:45:47.899+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:45:47.899+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:45:47.958+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:45:47.957+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:45:48.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.650 seconds
[2025-06-17T06:46:18.627+0000] {processor.py:157} INFO - Started process (PID=444) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:46:18.629+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:46:18.639+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:46:18.639+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:46:18.707+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:46:18.970+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:46:18.969+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:46:19.068+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:46:19.067+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:46:19.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.643 seconds
[2025-06-17T06:46:50.191+0000] {processor.py:157} INFO - Started process (PID=449) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:46:50.219+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:46:50.221+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:46:50.220+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:46:50.410+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:46:50.631+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:46:50.631+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:46:50.731+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:46:50.730+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:46:50.928+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.742 seconds
[2025-06-17T06:47:21.896+0000] {processor.py:157} INFO - Started process (PID=454) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:47:21.897+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:47:21.904+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:47:21.898+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:47:22.025+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:47:22.287+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:47:22.286+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:47:22.356+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:47:22.356+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:47:22.545+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.671 seconds
[2025-06-17T06:47:53.083+0000] {processor.py:157} INFO - Started process (PID=459) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:47:53.090+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:47:53.091+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:47:53.091+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:47:53.240+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:47:53.449+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:47:53.449+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:47:53.508+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:47:53.502+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:47:53.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.601 seconds
[2025-06-17T06:48:24.535+0000] {processor.py:157} INFO - Started process (PID=464) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:48:24.537+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:48:24.538+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:48:24.537+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:48:24.627+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:48:24.979+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:48:24.979+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:48:25.079+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:48:25.077+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:48:25.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.838 seconds
[2025-06-17T06:48:55.783+0000] {processor.py:157} INFO - Started process (PID=469) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:48:55.811+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:48:55.831+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:48:55.831+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:48:56.044+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:48:56.202+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:48:56.202+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:48:56.304+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:48:56.304+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:48:56.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.690 seconds
[2025-06-17T06:49:26.791+0000] {processor.py:157} INFO - Started process (PID=474) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:49:26.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:49:26.809+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:49:26.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:49:26.911+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:49:27.091+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:49:27.090+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:49:27.222+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:49:27.222+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:49:27.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.680 seconds
[2025-06-17T06:49:57.908+0000] {processor.py:157} INFO - Started process (PID=479) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:49:57.936+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:49:57.938+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:49:57.938+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:49:58.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:49:58.118+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:49:58.118+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:49:58.148+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:49:58.148+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:49:58.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.472 seconds
[2025-06-17T06:50:28.796+0000] {processor.py:157} INFO - Started process (PID=484) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:50:28.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:50:28.844+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:50:28.843+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:50:29.055+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:50:29.327+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:50:29.327+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:50:29.436+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:50:29.436+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:50:29.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.852 seconds
[2025-06-17T06:50:59.814+0000] {processor.py:157} INFO - Started process (PID=489) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:50:59.822+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:50:59.823+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:50:59.823+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:50:59.954+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:51:00.084+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:51:00.084+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:51:00.113+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:51:00.112+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:51:00.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.369 seconds
[2025-06-17T06:51:30.679+0000] {processor.py:157} INFO - Started process (PID=494) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:51:30.680+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:51:30.688+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:51:30.687+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:51:30.841+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:51:31.019+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:51:31.018+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:51:31.120+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:51:31.120+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:51:31.340+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.671 seconds
[2025-06-17T06:52:02.189+0000] {processor.py:157} INFO - Started process (PID=499) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:52:02.196+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:52:02.197+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:52:02.197+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:52:02.278+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:52:02.498+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:52:02.498+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:52:02.585+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:52:02.579+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:52:02.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.607 seconds
[2025-06-17T06:52:33.673+0000] {processor.py:157} INFO - Started process (PID=504) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:52:33.674+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:52:33.676+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:52:33.675+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:52:33.865+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:52:34.116+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:52:34.115+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:52:34.236+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:52:34.235+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:52:34.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.761 seconds
[2025-06-17T06:53:04.844+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:53:04.845+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:53:04.847+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:53:04.846+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:53:04.896+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:53:05.225+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:53:05.225+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:53:05.364+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:53:05.364+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:53:05.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.700 seconds
[2025-06-17T06:53:35.814+0000] {processor.py:157} INFO - Started process (PID=514) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:53:35.827+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:53:35.844+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:53:35.844+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:53:35.985+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:53:36.196+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:53:36.196+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:53:36.285+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:53:36.285+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:53:36.523+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.730 seconds
[2025-06-17T06:54:06.860+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:54:06.872+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:54:06.890+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:54:06.889+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:54:07.011+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:54:07.251+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:54:07.250+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:54:07.371+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:54:07.370+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:54:07.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.750 seconds
[2025-06-17T06:54:38.185+0000] {processor.py:157} INFO - Started process (PID=524) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:54:38.186+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:54:38.204+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:54:38.203+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:54:38.294+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:54:38.606+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:54:38.605+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:54:38.724+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:54:38.724+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:54:38.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.733 seconds
[2025-06-17T06:55:09.771+0000] {processor.py:157} INFO - Started process (PID=529) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:55:09.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:55:09.780+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:55:09.779+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:55:10.010+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:55:10.138+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:55:10.138+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:55:10.240+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:55:10.239+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:55:10.509+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.759 seconds
[2025-06-17T06:55:40.989+0000] {processor.py:157} INFO - Started process (PID=534) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:55:41.018+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:55:41.037+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:55:41.036+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:55:41.342+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:55:41.660+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:55:41.660+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:55:41.741+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:55:41.741+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:55:41.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.968 seconds
[2025-06-17T06:56:12.368+0000] {processor.py:157} INFO - Started process (PID=539) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:56:12.398+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:56:12.399+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:56:12.399+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:56:12.587+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:56:12.846+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:56:12.829+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:56:13.006+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:56:13.006+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:56:13.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.811 seconds
[2025-06-17T06:56:43.791+0000] {processor.py:157} INFO - Started process (PID=544) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:56:43.792+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:56:43.793+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:56:43.793+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:56:43.934+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:56:44.182+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:56:44.182+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:56:44.342+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:56:44.342+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:56:44.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.762 seconds
[2025-06-17T06:57:14.975+0000] {processor.py:157} INFO - Started process (PID=549) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:57:14.982+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:57:14.983+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:57:14.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:57:15.173+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:57:15.423+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:57:15.422+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:57:15.532+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:57:15.525+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:57:15.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.782 seconds
[2025-06-17T06:57:46.229+0000] {processor.py:157} INFO - Started process (PID=554) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:57:46.238+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:57:46.250+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:57:46.249+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:57:46.380+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:57:46.660+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:57:46.660+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:57:46.720+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:57:46.720+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:57:47.018+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.809 seconds
[2025-06-17T06:58:17.354+0000] {processor.py:157} INFO - Started process (PID=559) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:58:17.356+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:58:17.357+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:58:17.356+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:58:17.564+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:58:17.755+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:58:17.755+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:58:17.856+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:58:17.856+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:58:18.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.779 seconds
[2025-06-17T06:58:48.913+0000] {processor.py:157} INFO - Started process (PID=564) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:58:48.942+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:58:48.983+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:58:48.983+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:58:49.143+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:58:49.505+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:58:49.505+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:58:49.595+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:58:49.595+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:58:49.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.020 seconds
[2025-06-17T06:59:20.360+0000] {processor.py:157} INFO - Started process (PID=569) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:59:20.362+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:59:20.390+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:59:20.390+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:59:20.581+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:59:20.920+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:59:20.920+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:59:20.962+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:59:20.962+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:59:21.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.833 seconds
[2025-06-17T06:59:51.768+0000] {processor.py:157} INFO - Started process (PID=574) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:59:51.787+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T06:59:51.789+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:59:51.788+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:59:51.980+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T06:59:52.219+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:59:52.219+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T06:59:52.270+0000] {logging_mixin.py:151} INFO - [2025-06-17T06:59:52.269+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T06:59:52.470+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.733 seconds
[2025-06-17T07:00:22.938+0000] {processor.py:157} INFO - Started process (PID=579) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:00:22.999+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:00:23.009+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:00:23.008+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:00:23.199+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:00:23.389+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:00:23.389+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:00:23.499+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:00:23.498+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:00:23.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.779 seconds
[2025-06-17T07:00:54.314+0000] {processor.py:157} INFO - Started process (PID=584) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:00:54.321+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:00:54.323+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:00:54.322+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:00:54.413+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:00:54.604+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:00:54.604+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:00:54.643+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:00:54.642+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:00:54.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.490 seconds
[2025-06-17T07:01:25.322+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:01:25.330+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:01:25.332+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:01:25.331+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:01:25.571+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:01:25.730+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:01:25.730+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:01:25.819+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:01:25.802+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:01:26.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.808 seconds
[2025-06-17T07:01:56.748+0000] {processor.py:157} INFO - Started process (PID=594) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:01:56.749+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:01:56.767+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:01:56.767+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:01:57.028+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:01:57.468+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:01:57.467+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:01:57.597+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:01:57.597+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:01:57.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.990 seconds
[2025-06-17T07:02:28.074+0000] {processor.py:157} INFO - Started process (PID=599) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:02:28.082+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:02:28.083+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:02:28.083+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:02:28.215+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:02:28.543+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:02:28.543+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:02:28.725+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:02:28.725+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:02:28.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.921 seconds
[2025-06-17T07:03:00.226+0000] {processor.py:157} INFO - Started process (PID=604) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:03:00.256+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:03:00.257+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:03:00.257+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:03:00.418+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:03:00.648+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:03:00.619+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:03:00.716+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:03:00.699+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:03:01.046+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.840 seconds
[2025-06-17T07:03:31.887+0000] {processor.py:157} INFO - Started process (PID=609) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:03:31.889+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:03:31.917+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:03:31.916+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:03:32.357+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:03:32.687+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:03:32.686+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:03:32.856+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:03:32.856+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:03:33.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.400 seconds
[2025-06-17T07:04:03.809+0000] {processor.py:157} INFO - Started process (PID=614) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:04:03.847+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:04:03.848+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:04:03.848+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:04:04.036+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:04:04.358+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:04:04.357+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:04:04.519+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:04:04.518+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:04:04.837+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.039 seconds
[2025-06-17T07:04:36.390+0000] {processor.py:157} INFO - Started process (PID=619) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:04:36.458+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:04:36.459+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:04:36.459+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:04:36.718+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:04:37.067+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:04:37.066+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:04:37.178+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:04:37.178+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:04:37.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.109 seconds
[2025-06-17T07:05:08.797+0000] {processor.py:157} INFO - Started process (PID=624) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:08.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:05:08.828+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:05:08.827+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:09.229+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:09.608+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:05:09.607+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:05:09.739+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:05:09.739+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:05:10.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.319 seconds
[2025-06-17T07:05:41.639+0000] {processor.py:157} INFO - Started process (PID=629) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:41.658+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:05:41.660+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:05:41.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:41.881+0000] {processor.py:839} INFO - DAG(s) dict_keys(['iceberg_table_creator']) retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:42.288+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:05:42.261+0000] {dag.py:2907} INFO - Sync 1 DAGs
[2025-06-17T07:05:42.519+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:05:42.519+0000] {dag.py:3677} INFO - Setting next_dagrun for iceberg_table_creator to None, run_after=None
[2025-06-17T07:05:42.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.352 seconds
[2025-06-17T07:05:50.929+0000] {processor.py:157} INFO - Started process (PID=634) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:50.930+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:05:50.961+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:05:50.960+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:51.319+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:05:51.268+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:05:51.320+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:05:51.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.770 seconds
[2025-06-17T07:06:22.783+0000] {processor.py:157} INFO - Started process (PID=639) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:06:22.814+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:06:22.863+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:06:22.863+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:06:23.233+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:06:23.125+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:06:23.234+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:06:23.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.989 seconds
[2025-06-17T07:06:54.579+0000] {processor.py:157} INFO - Started process (PID=644) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:06:54.621+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:06:54.710+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:06:54.710+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:06:55.092+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:06:54.959+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:06:55.122+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:06:55.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.938 seconds
[2025-06-17T07:07:26.530+0000] {processor.py:157} INFO - Started process (PID=649) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:07:26.549+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:07:26.569+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:07:26.569+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:07:26.791+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:07:26.730+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:07:26.809+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:07:27.079+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.598 seconds
[2025-06-17T07:07:58.174+0000] {processor.py:157} INFO - Started process (PID=654) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:07:58.185+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:07:58.197+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:07:58.187+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:07:58.564+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:07:58.405+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:07:58.585+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:07:58.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.820 seconds
[2025-06-17T07:08:30.598+0000] {processor.py:157} INFO - Started process (PID=659) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:08:30.647+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:08:30.678+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:08:30.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:08:30.958+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:08:30.878+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:08:30.958+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:08:31.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.729 seconds
[2025-06-17T07:09:02.098+0000] {processor.py:157} INFO - Started process (PID=664) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:09:02.117+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:09:02.169+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:09:02.169+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:09:02.487+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:09:02.389+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:09:02.499+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:09:02.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.690 seconds
[2025-06-17T07:09:33.588+0000] {processor.py:157} INFO - Started process (PID=669) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:09:33.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:09:33.618+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:09:33.617+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:09:33.908+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:09:33.749+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:09:33.908+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:09:34.248+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.710 seconds
[2025-06-17T07:10:05.404+0000] {processor.py:157} INFO - Started process (PID=674) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:10:05.413+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:10:05.414+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:10:05.414+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:10:05.522+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:10:05.504+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:10:05.524+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:10:05.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.460 seconds
[2025-06-17T07:10:36.769+0000] {processor.py:157} INFO - Started process (PID=679) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:10:36.778+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:10:36.788+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:10:36.781+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:10:37.049+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:10:36.999+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:10:37.050+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:10:37.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.589 seconds
[2025-06-17T07:11:08.078+0000] {processor.py:157} INFO - Started process (PID=684) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:08.088+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:11:08.117+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:11:08.089+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:08.577+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:11:08.557+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:11:08.578+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:08.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.869 seconds
[2025-06-17T07:11:40.485+0000] {processor.py:157} INFO - Started process (PID=689) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:40.504+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:11:40.514+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:11:40.505+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:41.036+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:11:41.013+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['./spark/conf:/home/spark/notebooks']}
[2025-06-17T07:11:41.094+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:41.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.931 seconds
[2025-06-17T07:11:44.779+0000] {processor.py:157} INFO - Started process (PID=694) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:44.798+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:11:44.809+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:11:44.799+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:45.248+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:11:45.229+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 11
    docker_url="unix://var/run/docker.sock",
    ^
SyntaxError: invalid syntax
[2025-06-17T07:11:45.249+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:11:45.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.900 seconds
[2025-06-17T07:12:04.609+0000] {processor.py:157} INFO - Started process (PID=699) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:12:04.639+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:12:04.658+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:12:04.657+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:12:05.078+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:12:05.040+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:12:05.079+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:12:05.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.789 seconds
[2025-06-17T07:12:36.617+0000] {processor.py:157} INFO - Started process (PID=704) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:12:36.635+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:12:36.647+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:12:36.636+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:12:37.065+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:12:37.015+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:12:37.066+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:12:37.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.869 seconds
[2025-06-17T07:22:39.122+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:22:39.132+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:22:39.183+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:22:39.182+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:22:39.563+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:22:39.473+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:22:39.593+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:22:40.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.931 seconds
[2025-06-17T07:23:10.826+0000] {processor.py:157} INFO - Started process (PID=176) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:23:10.857+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:23:10.897+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:23:10.896+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:23:11.638+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:23:11.459+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:23:11.688+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:23:12.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.330 seconds
[2025-06-17T07:23:43.968+0000] {processor.py:157} INFO - Started process (PID=189) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:23:43.997+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:23:44.078+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:23:44.078+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:23:47.058+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:23:46.927+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:23:47.078+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:23:47.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 3.531 seconds
[2025-06-17T07:24:19.110+0000] {processor.py:157} INFO - Started process (PID=196) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:24:19.120+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:24:19.161+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:24:19.160+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:24:19.640+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:24:19.510+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:24:19.669+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:24:19.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.940 seconds
[2025-06-17T07:24:51.272+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:24:51.291+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:24:51.372+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:24:51.372+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:24:51.892+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:24:51.792+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:24:51.942+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:24:52.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.400 seconds
[2025-06-17T07:25:23.728+0000] {processor.py:157} INFO - Started process (PID=208) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:25:23.739+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:25:23.848+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:25:23.829+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:25:24.427+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:25:24.327+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:25:24.467+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:25:25.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.471 seconds
[2025-06-17T07:25:57.828+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:25:57.848+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:25:57.959+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:25:57.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:26:00.139+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:25:59.589+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:26:00.339+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:26:02.699+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 4.941 seconds
[2025-06-17T07:26:36.690+0000] {processor.py:157} INFO - Started process (PID=226) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:26:36.712+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:26:37.071+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:26:36.971+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:26:39.171+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:26:38.621+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/c/Users/MuhammadAsad/objectives2/lakehouse_docker_setup/spark/jobs:/opt/spark_jobs']}
[2025-06-17T07:26:39.181+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:26:41.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 5.690 seconds
[2025-06-17T07:27:02.420+0000] {processor.py:157} INFO - Started process (PID=231) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:27:02.449+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:27:02.510+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:27:02.501+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:27:03.081+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:27:03.010+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:27:03.100+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:27:04.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 1.720 seconds
[2025-06-17T07:35:07.574+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:35:08.323+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:35:08.534+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:35:08.533+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:35:11.394+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:35:10.953+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:35:11.404+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:35:14.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 8.009 seconds
[2025-06-17T07:35:55.509+0000] {processor.py:157} INFO - Started process (PID=176) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:35:56.259+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:35:57.048+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:35:57.018+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:36:02.658+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:36:01.608+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:36:02.688+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:36:09.108+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 17.560 seconds
[2025-06-17T07:36:43.952+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:36:44.581+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:36:45.801+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:36:45.602+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:36:48.241+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:36:47.692+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:36:48.292+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:36:51.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 8.120 seconds
[2025-06-17T07:37:30.499+0000] {processor.py:157} INFO - Started process (PID=186) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:37:30.719+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:37:31.679+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:37:31.678+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:38:41.130+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:38:40.890+0000] {timeout.py:68} ERROR - Process timed out, PID: 186
[2025-06-17T07:38:41.150+0000] {logging_mixin.py:151} WARNING - Exception ignored in: <function _collection_gced at 0x7fcfafd810d0>
[2025-06-17T07:38:41.270+0000] {logging_mixin.py:151} WARNING - Traceback (most recent call last):
[2025-06-17T07:38:41.360+0000] {logging_mixin.py:151} WARNING -   File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/event/registry.py", line 53, in _collection_gced
[2025-06-17T07:38:41.380+0000] {logging_mixin.py:151} WARNING -     def _collection_gced(ref):
[2025-06-17T07:38:41.390+0000] {logging_mixin.py:151} WARNING -   File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timeout.py", line 69, in handle_timeout
[2025-06-17T07:38:41.430+0000] {logging_mixin.py:151} WARNING -     raise AirflowTaskTimeout(self.error_message)
[2025-06-17T07:38:41.450+0000] {logging_mixin.py:151} WARNING - airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/iceberg_job_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.7.0/best-practices.html#reducing-dag-complexity, PID: 186
[2025-06-17T07:38:42.010+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:38:41.630+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:38:42.040+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:39:15.549+0000] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:39:15.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:39:15.679+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:39:15.659+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:39:16.819+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:39:16.479+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:39:16.879+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:39:18.159+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 2.840 seconds
[2025-06-17T07:39:53.356+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:39:53.616+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:39:54.126+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:39:54.116+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:39:57.296+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:39:55.956+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:39:57.456+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:40:01.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 9.580 seconds
[2025-06-17T07:40:35.493+0000] {processor.py:157} INFO - Started process (PID=208) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:40:35.614+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:40:35.804+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:40:35.724+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:40:37.194+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:40:36.954+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:40:37.233+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:40:38.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 2.860 seconds
[2025-06-17T07:41:11.985+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:41:12.315+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:41:12.804+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:41:12.735+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:41:14.965+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:41:14.655+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:41:15.025+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:41:18.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 7.119 seconds
[2025-06-17T07:41:53.978+0000] {processor.py:157} INFO - Started process (PID=219) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:41:54.198+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:41:54.578+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:41:54.508+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:41:57.108+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:41:56.628+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:41:57.218+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:42:00.958+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 7.520 seconds
[2025-06-17T07:42:36.408+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:42:36.628+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:42:37.619+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:42:37.588+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:42:39.518+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:42:39.039+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:42:39.539+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:42:42.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 7.920 seconds
[2025-06-17T07:43:16.936+0000] {processor.py:157} INFO - Started process (PID=229) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:43:17.045+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:43:17.355+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:43:17.355+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:43:19.945+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:43:19.066+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:43:20.015+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:43:23.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 7.149 seconds
[2025-06-17T07:44:01.358+0000] {processor.py:157} INFO - Started process (PID=235) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:44:01.587+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:44:01.898+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:44:01.838+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:44:05.498+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:44:04.448+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:44:05.638+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:44:10.158+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 10.650 seconds
[2025-06-17T07:44:46.437+0000] {processor.py:157} INFO - Started process (PID=249) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:44:47.086+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:44:47.966+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:44:47.887+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:44:51.467+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:44:49.776+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:44:52.076+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:44:55.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 10.650 seconds
[2025-06-17T07:45:31.653+0000] {processor.py:157} INFO - Started process (PID=256) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:45:31.813+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:45:32.303+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:45:32.273+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:45:34.113+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:45:33.573+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:45:34.223+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:45:39.213+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 8.250 seconds
[2025-06-17T07:46:13.866+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:46:13.986+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:46:14.316+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:46:14.266+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:46:16.906+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:46:16.146+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:46:17.156+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:46:19.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 6.120 seconds
[2025-06-17T07:46:55.708+0000] {processor.py:157} INFO - Started process (PID=267) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:46:55.948+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:46:56.218+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:46:56.188+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:46:59.038+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:46:58.538+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:46:59.168+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:47:01.728+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 6.230 seconds
[2025-06-17T07:53:31.220+0000] {processor.py:157} INFO - Started process (PID=170) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:53:31.222+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:53:31.225+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:53:31.225+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:53:31.251+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:53:31.247+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:53:31.251+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:53:31.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.368 seconds
[2025-06-17T07:54:01.798+0000] {processor.py:157} INFO - Started process (PID=196) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:54:01.799+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:54:01.806+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:54:01.806+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:54:01.827+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:54:01.823+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:54:01.828+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:54:01.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.084 seconds
[2025-06-17T07:54:32.031+0000] {processor.py:157} INFO - Started process (PID=207) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:54:32.033+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:54:32.036+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:54:32.035+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:54:32.291+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:54:32.286+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:54:32.291+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:54:32.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.304 seconds
[2025-06-17T07:55:02.761+0000] {processor.py:157} INFO - Started process (PID=212) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:55:02.763+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:55:02.778+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:55:02.776+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:55:02.810+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:55:02.799+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:55:02.812+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:55:02.856+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.103 seconds
[2025-06-17T07:55:32.955+0000] {processor.py:157} INFO - Started process (PID=217) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:55:32.956+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:55:32.959+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:55:32.958+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:55:32.976+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:55:32.972+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:55:32.977+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:55:33.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.051 seconds
[2025-06-17T07:56:03.408+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:56:03.411+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:56:03.421+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:56:03.421+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:56:03.697+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:56:03.673+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:56:03.704+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:56:04.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.670 seconds
[2025-06-17T07:56:34.399+0000] {processor.py:157} INFO - Started process (PID=227) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:56:34.428+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:56:34.519+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:56:34.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:56:34.634+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:56:34.602+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:56:34.639+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:56:35.211+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.851 seconds
[2025-06-17T07:57:05.506+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:57:05.508+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:57:05.519+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:57:05.518+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:57:05.564+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:57:05.558+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:57:05.565+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:57:05.627+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.126 seconds
[2025-06-17T07:57:35.728+0000] {processor.py:157} INFO - Started process (PID=237) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:57:35.738+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:57:35.743+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:57:35.743+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:57:35.773+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:57:35.764+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:57:35.773+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:57:35.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.152 seconds
[2025-06-17T07:58:05.927+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:58:05.931+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:58:05.934+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:58:05.934+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:58:05.954+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:58:05.948+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:58:05.955+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:58:06.013+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.089 seconds
[2025-06-17T07:58:36.141+0000] {processor.py:157} INFO - Started process (PID=247) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:58:36.149+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:58:36.152+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:58:36.151+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:58:36.180+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:58:36.169+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:58:36.180+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:58:36.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.093 seconds
[2025-06-17T07:59:06.377+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:06.380+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:59:06.383+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:59:06.382+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:06.402+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:59:06.398+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:59:06.403+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:06.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.060 seconds
[2025-06-17T07:59:36.567+0000] {processor.py:157} INFO - Started process (PID=257) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:36.569+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:59:36.573+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:59:36.572+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:36.590+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:59:36.587+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 7, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:59:36.591+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:36.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.062 seconds
[2025-06-17T07:59:58.733+0000] {processor.py:157} INFO - Started process (PID=262) to work on /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:58.734+0000] {processor.py:829} INFO - Processing file /opt/airflow/dags/iceberg_job_dag.py for tasks to queue
[2025-06-17T07:59:58.738+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:59:58.737+0000] {dagbag.py:539} INFO - Filling up the DagBag from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:58.767+0000] {logging_mixin.py:151} INFO - [2025-06-17T07:59:58.763+0000] {dagbag.py:347} ERROR - Failed to import: /opt/airflow/dags/iceberg_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 343, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/iceberg_job_dag.py", line 17, in <module>
    run_spark_job = DockerOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/docker/operators/docker.py", line 226, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 436, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_spark_job). Invalid arguments were:
**kwargs: {'volumes': ['/opt/airflow/spark_jobs:/opt/spark_jobs']}
[2025-06-17T07:59:58.768+0000] {processor.py:841} WARNING - No viable dags retrieved from /opt/airflow/dags/iceberg_job_dag.py
[2025-06-17T07:59:58.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/iceberg_job_dag.py took 0.080 seconds
